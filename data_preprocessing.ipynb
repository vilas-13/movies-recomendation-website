import pandas as pd
import numpy as np
import ast
movie_file = pd.read_csv('tmdb_5000_movies.csv')   // dataset containing details of the movie
credit_file = pd.read_csv('tmdb_5000_credits.csv') //dataset of cast and crew in the movie
movie_file.head(1)
credit_file.head(1)
// merging both datails of the movies and credits of the movies into 1 dataset
mvf=movie_file.merge(credit_file, on = 'title')
mvf.head(1)
//taking only required details of the movie to build, can be more or less depends on how you want to build the project
mvf=mvf[['movie_id','title','overview','genres', 'keywords','cast','crew']]
//droping the things which does contiain any value/null
mvf.dropna(inplace=True)
mvf.iloc[0].genres
//This function removes unnessery variables in genre and keywords to get clear info of our dataset
def convert(obj):
    l=[]
    for i in ast.literal_eval(obj):
        l.append(i['name'])
    return l
mvf['genres']=mvf['genres'].apply(convert)
mvf['keywords']=mvf['keywords'].apply(convert)
mvf.head(1)
// the function which to remove unneccesary variables from cast but returns us only top 3 cast from the movies
def convert2(obj):
    l=[]
    count =0
    for i in ast.literal_eval(obj):
        if count!=3:
            l.append(i['name'])
            count+=1
        else:
            break
    return l
mvf['cast']=mvf['cast'].apply(convert)
//function to get only director of the movie from the crew
def search_dec(obj):
    l=[]
    for i in ast.literal_eval(obj):
        if i['job']=='Director':
            l.append(i['name'])
            break
    return l
mvf['crew']=mvf['crew'].apply(search_dec)

mvf['overview'][0]
//separating each word in the overview, genres, keywords,cast and crew by ","
mvf['overview']=mvf['overview'].apply(lambda y:y.split())
mvf['genres']=mvf['genres'].apply(lambda y:[i.replace(" ","")for i in y])
mvf['keywords']=mvf['keywords'].apply(lambda y:[i.replace(" ","")for i in y])
mvf['cast']=mvf['cast'].apply(lambda y:[i.replace(" ","")for i in y])
mvf['crew']=mvf['crew'].apply(lambda y:[i.replace(" ","")for i in y])

//creating a subset tags by combining all overview, genres , keywords , cast and crew, so the further process becomes easy
mvf['tags']=mvf['overview']+ mvf['genres']+ mvf['keywords']+ mvf['cast']+mvf['crew']
mvf.head()
//creating a dataset of only required sub datasets
mvf1=mvf[['movie_id','title','tags']]
mvf1.head()
//converting all letter in tags into lowercase
mvf1['tags']=mvf1['tags'].apply(lambda y:y.lower())
mvf1.head()

import nltk
from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()
//converting all similar words into one word using steming in tags
def stem(text):
    a=[]
    for i in text.split():
        a.append(ps.stem(i))
    return " ".join(a)
mvf1['tags']=mvf1['tags'].apply(stem)

from sklearn.feature_extraction.text import CountVectorizer
// cv is an object which vectorizes every movie in dataset, here max_featues will tell how many words you want to takes since there are 5000 movies so i took 5000 words,
// and stop_words will remove all the unrequired words in english
cv=CountVectorizer(max_features=5000,stop_words='english') 
//converting tags into numpy array
vectors=cv.fit_transform(mvf1['tags']).toarray()
vectors[0]

from sklearn.metrics.pairwise import cosine_similarity
//creating vectors for each movie in the form multiple dimention
similarities=cosine_similarity(vectors)
//creating a list of top 5 vectos of the movies which are near to the given movie of the dataset and sorting them from top 1 to bottom
sorted(list(enumerate(similarities[0])),reverse=True, key=lambda x:x[1])[1:6]

def recommend(movies):
    //TO get the titles of the similar movies
    mvf1_index=mvf1[mvf1['title']==movies].index[0]
    //calculating the angle between each movie vectors
    distance=similarities[mvf1_index]
    rec_list=sorted(list(enumerate(distance)),reverse=True, key=lambda x:x[1])[1:6] //creating dataset of top 5 recommending movies for each movie in the given dataset
    
    for i in rec_list:
        print(mvf1.iloc[i[0]].title) //to print top 5 best similar movies in the given dataset
recommend('Iron Man 2')

import pickle
//creating a file named "movie_dict.pkl" in the form of dictinary which contains all the requaired data 
pickle.dump(mvf1.to_dict(),open('movie_dict.pkl','wb'))
//creating a file "similar_movies.pkl" which contains all the dataset of similarities variable
pickle.dump(similarities,open('Similar_movies.pkl','wb'))
